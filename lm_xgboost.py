# -*- coding: utf-8 -*-
"""lm_xgboost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LgMDOn_RPBk1gILnycLHgXxe3DmxwddD
"""

from IPython import get_ipython
from IPython.display import display
# %%
import pandas as pd
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from scipy.stats import randint, uniform
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

class LXgboost:
    pass

def load_and_preprocess_data(file_path):
      """Loads the data, performs preprocessing, and returns it.
      Args:
          file_path (str): The path to the CSV file.
      Returns:
          pandas.DataFrame: The preprocessed DataFrame.
      """
      df = pd.read_csv(file_path, dtype={'InvoiceNo': str})

      # Create the 'total_price' column
      df['total_price'] = df['Quantity'] * df['UnitPrice']

      # Convert 'InvoiceDate' to datetime
      df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])

      # Create the daily variables
      df_daily = df.groupby('InvoiceDate').agg(
          daily=('Quantity', lambda x: x[x > 0].sum()),
          daily_sells=('InvoiceNo', 'nunique'),
          daily_total=('total_price', lambda x: x[x > 0].sum()),
          day_of_week=('InvoiceDate', lambda x: x.iloc[0].dayofweek)
      )

      # Select the numerical columns to standardize
      numerical_cols = ['daily', 'daily_sells', 'daily_total']

      # Standardize the numerical columns
      scaler = StandardScaler()
      df_daily[numerical_cols] = scaler.fit_transform(df_daily[numerical_cols])

      return df_daily

def split_data(df_daily):
    """Splits the data into training, validation, and test sets.
    Args:
        df_daily (pd.DataFrame): The preprocessed daily DataFrame.
    Returns:
        tuple: A tuple containing the training, validation, and test DataFrames.
    """
    # Filter data between December 1, 2010 and November 8, 2011
    data_train_val = df_daily[(df_daily.index >= datetime(2010, 12, 1)) & (df_daily.index <= datetime(2011, 11, 8))]

    # Split into training and validation sets (80% and 20%)
    df_daily_train, df_daily_val = train_test_split(data_train_val, test_size=0.2, random_state=42)

    # Filter data for the test set (after November 8, 2011)
    df_daily_test = df_daily[(df_daily.index >= datetime(2011, 11, 9)) & (df_daily.index <= datetime(2011, 12, 9))]

    # Print the size of the sets
    print(f"Training set size: {df_daily_train.shape[0]}")
    print(f"Validation set size: {df_daily_val.shape[0]}")
    print(f"Test set size: {df_daily_test.shape[0]}")

    return df_daily_train, df_daily_val, df_daily_test

def train_xgboost_model(df_daily_train, df_daily_val):
      """Trains an XGBoost model for sales quantity and total revenue prediction.
      Args:
          df_daily_train (pd.DataFrame): The training DataFrame.
          df_daily_val (pd.DataFrame): The validation DataFrame.
      Returns:
          tuple: A tuple containing the trained XGBoost models for quantity and total.
      """
      # Define features and target variables
      features = ['daily_sells', 'day_of_week', 'daily_total']
      target_quantity = 'daily'
      target_total = 'daily_total'

       # Define the hyperparameter distributions
      param_dist = {
          'n_estimators': randint(100, 500),  # Uniform distribution between 100 and 500
          'learning_rate': uniform(0.01, 0.3), # Uniform distribution between 0.01 and 0.3
          'max_depth': randint(3, 10),        # Uniform distribution between 3 and 10
          'subsample': uniform(0.5, 0.5),      # Uniform distribution between 0.5 and 1 (0.5 + 0.5)
          'colsample_bytree': uniform(0.5, 0.5) # Uniform distribution between 0.5 and 1 (0.5 + 0.5)
      }

      # Create and train XGBoost model for quantity with hyperparameter tuning
      xgb_quantity = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
      random_search = RandomizedSearchCV(
          estimator=xgb_quantity,
          param_distributions=param_dist,
          n_iter=10,  # Number of random combinations to try
          scoring='neg_mean_squared_error',
          cv=5,  # Number of cross-validation folds
          verbose=1,
          random_state=42  # For reproducibility
      )
      random_search.fit(df_daily_train[features], df_daily_train[target_quantity])

      # Get the best model and its hyperparameters
      best_xgb_quantity = random_search.best_estimator_

      # Create and train XGBoost model for total revenue
      xgb_total = xgb.XGBRegressor(**best_xgb_quantity.get_params())  # Reuse hyperparameters, as quantity and total revenue are highly correlated
      xgb_total.fit(df_daily_train[features], df_daily_train[target_total],
                eval_set=[(df_daily_val[features], df_daily_val[target_total])])

      return best_xgb_quantity, xgb_total

def predict_sales(xgb_quantity, xgb_total, df_daily_test):
    """Predicts sales quantity and total revenue using the trained XGBoost models.
    Args:
        xgb_quantity (xgboost.XGBRegressor): The trained XGBoost model for quantity prediction.
        xgb_total (xgboost.XGBRegressor): The trained XGBoost model for total revenue prediction.
        df_daily_test (pd.DataFrame): The test DataFrame.
    Returns:
        pd.DataFrame: The test DataFrame with added 'predicted_quantity' and 'predicted_total' columns.
    """
    # Define the features for prediction
    features = ['daily_sells', 'day_of_week', 'daily_total']

    # Make a copy to prevent SettingWithCopyWarning
    df_with_predictions = df_daily_test.copy()  # Make a copy of df_daily_test

    # Make predictions and assign to new columns
    df_with_predictions['predicted_quantity'] = xgb_quantity.predict(df_daily_test[features])  # Assign to a new column
    df_with_predictions['predicted_total'] = xgb_total.predict(df_daily_test[features])      # Assign to a new column

    return df_with_predictions  # Return the copy with predictions

def evaluate_model(df_with_predictions, target_column, prediction_column):
    """Evaluates the model's performance using regression metrics.
    Args:
        df_with_predictions (pd.DataFrame): The DataFrame containing actual and predicted values.
        target_column (str): The name of the column containing the actual target values.
        prediction_column (str): The name of the column containing the predicted values.
    """
    # Calculate evaluation metrics
    mse = mean_squared_error(df_with_predictions[target_column], df_with_predictions[prediction_column])
    rmse = mse**0.5  # Root Mean Squared Error
    mae = mean_absolute_error(df_with_predictions[target_column], df_with_predictions[prediction_column])
    r2 = r2_score(df_with_predictions[target_column], df_with_predictions[prediction_column])

    # Print the evaluation metrics
    print(f"Mean Squared Error (MSE): {mse:.4f}")
    print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"Mean Absolute Error (MAE): {mae:.4f}")
    print(f"R-squared (R2): {r2:.4f}")

def visualize_predictions(df_with_predictions, title_quantity, title_total):
      """Visualizes predictions against actual values.
      Args:
          df_with_predictions (pd.DataFrame): DataFrame containing actual and predicted values.
          title (str): Title for the plot.
      """
      plt.figure(figsize=(12, 6))

      # Plot for Quantity
      plt.figure(figsize=(12, 6))
      plt.plot(df_with_predictions.index, df_with_predictions['daily'], label='Actual Quantity', color='blue')
      plt.plot(df_with_predictions.index, df_with_predictions['predicted_quantity'], label='Predicted Quantity', color='red', linestyle='--')
      plt.title(title_quantity)
      plt.xlabel('Date')
      plt.ylabel('Quantity')
      plt.legend()
      plt.grid(True)
      plt.show()

      # Plot for Total Revenue
      plt.figure(figsize=(12, 6))
      plt.plot(df_with_predictions.index, df_with_predictions['daily_total'], label='Actual Total Revenue', color='green')
      plt.plot(df_with_predictions.index, df_with_predictions['predicted_total'], label='Predicted Total Revenue', color='orange', linestyle='--')
      plt.title(title_total)
      plt.xlabel('Date')
      plt.ylabel('Total Revenue')
      plt.legend()
      plt.grid(True)
      plt.show()

      # Create residual plots (difference between preditions and actual values)
      residuals = df_daily_test['daily'] - df_daily_test['predicted_quantity']
      plt.scatter(df_daily_test['predicted_quantity'], residuals)
      plt.axhline(y=0, color='r', linestyle='--')
      plt.xlabel('Predicted Quantity')
      plt.ylabel('Residuals')
      plt.title('Residual Plot for Quantity')
      plt.show()

def run(file_path='data/clean_data.csv'):
    """
    Función principal que ejecuta el flujo de trabajo completo.

    Args:
        file_path (str, optional): La ruta al archivo CSV.
                                    Por defecto: 'data/clean_data.csv'.
    """
    df_daily = load_and_preprocess_data(file_path)
    df_daily_train, df_daily_val, df_daily_test = split_data(df_daily)
    xgb_quantity, xgb_total = train_xgboost_model(df_daily_train, df_daily_val)
    df_daily_test = predict_sales(xgb_quantity, xgb_total, df_daily_test)

    # Evaluar el modelo
    print("Evaluación para la Cantidad:")
    evaluate_model(df_daily_test, 'daily', 'predicted_quantity')
    print("\nEvaluación para el Ingreso Total:")
    evaluate_model(df_daily_test, 'daily_total', 'predicted_total')

    # Visualizar las predicciones
    visualize_predictions(df_daily_test, 'Predicciones de Cantidad en el Conjunto de Prueba',
                          'Predicciones de Ingresos Totales en el Conjunto de Prueba')